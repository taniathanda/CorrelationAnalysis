{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGDxEc1yhSlZ"
   },
   "source": [
    "# 1. Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1738370218509,
     "user": {
      "displayName": "tania thandar",
      "userId": "13865092197777207227"
     },
     "user_tz": 300
    },
    "id": "oe8mtfnYhREh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "original_df = pd.read_csv(\"/content/drive/MyDrive/Data Science/nba.csv\")\n",
    "#print(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8y_mpoohm9x"
   },
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1738370228244,
     "user": {
      "displayName": "tania thandar",
      "userId": "13865092197777207227"
     },
     "user_tz": 300
    },
    "id": "-Ggt3nVcfytJ"
   },
   "outputs": [],
   "source": [
    "# Removing any rows with blanks or nulls.\n",
    "original_df.dropna(inplace=True)\n",
    "\n",
    "# Removing duplicate rows\n",
    "original_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Shuffle data and define train-test split (80% is for training, 20% is for testing)\n",
    "train_df = original_df.sample(frac=0.8, random_state=50) # First 80% for training\n",
    "test_df = original_df.drop(train_df.index) # Remaining 20% for testing\n",
    "#print(train_df)\n",
    "#print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTvp6Uj_h-VD"
   },
   "source": [
    "# 3. Statistical Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 189,
     "status": "ok",
     "timestamp": 1738370231117,
     "user": {
      "displayName": "tania thandar",
      "userId": "13865092197777207227"
     },
     "user_tz": 300
    },
    "id": "cdUU8pTwiDuA",
    "outputId": "910a0c4c-adf5-4624-85ab-2f2920d08eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical description for training dataset:\n",
      "           Number         Age      Weight        Salary\n",
      "count  291.000000  291.000000  291.000000  2.910000e+02\n",
      "mean    16.652921   26.718213  218.752577  4.707358e+06\n",
      "std     14.653933    4.200531   24.527549  5.161403e+06\n",
      "min      0.000000   19.000000  161.000000  5.572200e+04\n",
      "25%      5.000000   24.000000  200.000000  1.011224e+06\n",
      "50%     12.000000   26.000000  220.000000  2.525160e+06\n",
      "75%     24.000000   29.000000  238.000000  6.315702e+06\n",
      "max     99.000000   40.000000  275.000000  2.287500e+07\n",
      "\n",
      "Statistical description for testing dataset:\n",
      "          Number        Age      Weight        Salary\n",
      "count  73.000000  73.000000   73.000000  7.300000e+01\n",
      "mean   17.534247  26.205479  223.904110  4.273317e+06\n",
      "std    16.369078   4.368317   25.582744  4.969561e+06\n",
      "min     0.000000  20.000000  175.000000  5.572200e+04\n",
      "25%     5.000000  23.000000  205.000000  9.472760e+05\n",
      "50%    12.000000  25.000000  225.000000  2.500000e+06\n",
      "75%    30.000000  28.000000  245.000000  5.103120e+06\n",
      "max    90.000000  36.000000  279.000000  2.219273e+07\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical description for training dataset:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"\\nStatistical description for testing dataset:\")\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fCgCw6izaK5"
   },
   "source": [
    "### Interpretation of Statistical Description\n",
    "\n",
    "Count = Number of non-null values in each column.\n",
    "\n",
    "Mean = Average value of each column.\n",
    "\n",
    "Std(Standard Deviation) = Measures how spread out the values are.\n",
    "\n",
    "Min = Smallest value in each column.\n",
    "\n",
    "25% = First quartile (25th percentile).\n",
    "\n",
    "50% = Middle value.\n",
    "\n",
    "75% = Third quartile (75th percentile).\n",
    "\n",
    "Max = Largest value in each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVmGUQabipso"
   },
   "source": [
    "# 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1738371713603,
     "user": {
      "displayName": "tania thandar",
      "userId": "13865092197777207227"
     },
     "user_tz": 300
    },
    "id": "i12xHjGyis7g",
    "outputId": "c0a29017-4959-483f-e64d-945f75850400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Matrix for Salaries of Selected Teams:\n",
      "                 Boston Celtics  Brooklyn Nets  New York Knicks\n",
      "Boston Celtics         1.000000      -0.102263        -0.128966\n",
      "Brooklyn Nets         -0.102263       1.000000         0.304434\n",
      "New York Knicks       -0.128966       0.304434         1.000000\n"
     ]
    }
   ],
   "source": [
    "# selecting 3 teams to filter\n",
    "dataframe_Boston = original_df.loc[original_df['Team'] == 'Boston Celtics']\n",
    "dataframe_Brooks = original_df.loc[original_df['Team'] == 'Brooklyn Nets']\n",
    "dataframe_NewYork = original_df.loc[original_df['Team'] == 'New York Knicks']\n",
    "# print(dataframe_Boston)\n",
    "\n",
    "# Merging 3 data frames of 3 teams into one dataframe\n",
    "merged_dataframe = pd.concat([dataframe_Boston, dataframe_Brooks, dataframe_NewYork])\n",
    "# print(merged_dataframe)\n",
    "\n",
    "# Creating salary list of each team\n",
    "boston_salaries = merged_dataframe[merged_dataframe['Team'] == \"Boston Celtics\"][\"Salary\"].reset_index(drop=True)\n",
    "brooklyn_salaries = merged_dataframe[merged_dataframe['Team'] == \"Brooklyn Nets\"][\"Salary\"].reset_index(drop=True)\n",
    "newyork_salaries = merged_dataframe[merged_dataframe['Team'] == \"New York Knicks\"][\"Salary\"].reset_index(drop=True)\n",
    "# print(boston_salaries)\n",
    "\n",
    "# Combining salaries of three teams\n",
    "salary_dataframe = pd.DataFrame({\n",
    "    \"Boston Celtics\": boston_salaries,\n",
    "    \"Brooklyn Nets\": brooklyn_salaries,\n",
    "    \"New York Knicks\": newyork_salaries\n",
    "})\n",
    "\n",
    "# Removing any rows with blanks or nulls\n",
    "salary_dataframe.dropna(inplace=True)\n",
    "\n",
    "# Removing duplicate rows\n",
    "salary_dataframe.drop_duplicates(inplace=True)\n",
    "# print(salary_dataframe)\n",
    "\n",
    "# Computing correlation between salaries columns\n",
    "correlation = salary_dataframe.corr()\n",
    "\n",
    "print(\"\\nCorrelation Matrix for Salaries of Selected Teams:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN9SyuOP4ZA2"
   },
   "source": [
    "### Insights of Correlation Analysis\n",
    "\n",
    "1 = Strong Positive Correlation/ 0= No Correlation/ -1= Strong Negative Correlation\n",
    "\n",
    "Based on the result of first row,\n",
    "\n",
    "Boston Celtics & Boston Celtics = 1 = Self correlation\n",
    "\n",
    "Boston Celtics & Brooklyn Nets = -0.102263 (Strong Negative correlation)\n",
    "\n",
    "Boston Celtics & New York Knicks = -0.128966 (Strong Negative correlation)\n",
    "\n",
    "Based on the result of second row,\n",
    "\n",
    "Brooklyn Nets & Boston Celtics = -0.102263 (Strong Negative correlation)\n",
    "\n",
    "Brooklyn Nets & Brooklyn Nets = 1 = Self correlation\n",
    "\n",
    "Boston Celtics & New York Knicks = 0.304434 (Weak Positive correlation)\n",
    "\n",
    "Based on the result of second row,\n",
    "\n",
    "New York Knicks & Boston Celtics = -0.128966 (Strong Negative correlation)\n",
    "\n",
    "New York Knicks & Brooklyn Nets = 0.304434 (Weak Positive correlation)\n",
    "\n",
    "New York Knicks & New York Knicks = 1 = Self correlation\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM9XLCzuTclS9/HgIpPB682",
   "collapsed_sections": [
    "_8y_mpoohm9x",
    "hTvp6Uj_h-VD",
    "bVmGUQabipso"
   ],
   "mount_file_id": "1VzxAmR8XJoBzChSxy0FysZL8tSBqhCwK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
